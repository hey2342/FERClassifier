00_TrainBase.sh            エンコーダのベースを学習
01_TrainClassifier.sh      エンコーダをBU3DFEで学習
02_NeutralFeature.sh       学習時の人物の無表情の特徴量を抽出
03_FeatureExtraction.sh    テスト画像の特徴抽出
04_Eval.sh                 異常検出と表情の有無の分類



テストしたい場合
0.元画像を正面化し、目、口の画像とランドマークを用意してください。
　 画像はpngファイル、ランドマークはnumpyファイル(3次元、68点)で用意してください。
   元画像がhoge.pngの場合、正面化した各画像はhoge.png、ランドマークはhoge.npyという風に同じ名前にしてください。
    <path/to/dataset/>movie/元画像    (動画を画像にしたもの)
                  |-  data/顔画像     (正面化する前の顔画像、使わないのでなくても大丈夫です)
                  |-  np/ランドマーク    (正面化したランドマーク)
                  |-  leye/左目画像    (正面化した左目画像)
                  |-  reye/右目画像    (正面化した右目画像)
                  |-  mouth/口画像     (正面化した口画像)
  

1. ListImages/Test_sample_youtube.txt と同じようにリストを作成
    上で用意した目、口の画像、ランドマークを読み込んで特徴抽出するためのリストです。
    例えば、無表情顔のhoge.pngを読み込みたい場合
        <path/to/dataset/>data/hoge.png 0
    と書きます。表情がある場合ラベルは0ではなく1です。
    テスト時はラベルが基本的にないので全部0or1でも大丈夫です。
2. 03_FeatureExtraction.sh で特徴抽出。
    forループの中身は以下のような形になってます
        python Encoder test <1で用意したリスト> -c <学習済みのモデル> -f <特徴量の出力先>
    1で用意したリストの名前を変えたり、特徴量の出力先を変えたい場合は適宜入力の名前を変えてください。
3. 04_Eval.sh で表情表出の検出
    2で用意した特徴量を使って表情の2クラス識別をします。
    
    1つ目のforループの中身は以下。
        python AnomalyDetection.py <閾値> <結果の出力先>
    閾値はデータ全体で表情の出ているものが何割含まれていることにして表情の有無を推定するかを表します。
    たとえば05にすると5%、20にすると20%です。
    この数字が高いほど表情の識別がゆるくなるので、表情が出ている画像を拾いやすくなる代わりに、無表情の画像を表情有りに間違えるケースも増えます。
    第二引数は出力先のフォルダです。
    この中に prediction_<閾値>/ という名前のフォルダが作られ、その下に特徴抽出器の数だけ2クラス識別の結果がnumpyファイルで出力されます。
    
    2つ目のforループの中身は以下。
        python 
    
    test_label.npyに動画中でどのフレームを使うかが入ってる
        (手元の動画で表情有りのフレームが多かったので調整してるだけ)
        (-1,0,1のnumpy配列、-1は使わない0と1は使う、特になにもしない場合は動画の総フレーム数分1を並べた配列を読ませればok)



モデルを追加したい場合
[MUG dataset](https://mug.ee.auth.gr/fed/)
[BU3DFE database](http://www.cs.binghamton.edu/~lijun/Research/3DFE/3DFE_Analysis.html)
を使いました。
BU3DFEのF0001〜F0020とM0001〜M0020の人物については学習済みです。
それ以外の人を使いたい場合だけ、読んでください。
0. 00_TrainBase.shでベースの学習 (classifier_baseがこれの出力なので無視しても良いです) 
    正面向きの表情がはっきり出ている画像で無表情とそれ以外の2クラス識別を学習します。
    MUG dataset を使いました。
    入力ファイル名とその内容(ListImages/Train_001.txtなど)は必要に応じて変えてください。
1. 01_TrainClassifier.shで学習
    0で学習したモデルをベースにBU3DFEで学習します。
    BU3DFE database を使いました。
    こちらも適宜入力等変えてください、デフォルトのものは既に学習済みです。
2. 02_NeutralFeature.shで無表情の顔画像の特徴抽出
    1で学習したモデルを使って学習に用いた同一人物の無表情の顔画像の特徴抽出を行います。
    1と同様にデフォルトのものは既に特徴抽出までできてます。
